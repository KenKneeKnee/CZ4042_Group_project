{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pytreebank\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pytreebank.load_sst(\"data/SST2-Data/SST2-Data/trainDevTestTrees_PTB/trees/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(\"data/sst_{}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with <_io.TextIOWrapper name='data/sst_train.txt' mode='w' encoding='UTF-8'>\n",
      "done with <_io.TextIOWrapper name='data/sst_test.txt' mode='w' encoding='UTF-8'>\n",
      "done with <_io.TextIOWrapper name='data/sst_dev.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "for cat in ['train','test','dev']:\n",
    "    with open(out_path.format(cat),\"w\") as file:\n",
    "        for item in data[cat]:\n",
    "            file.write(\"__label__{}\\t{}\\n\".format(\n",
    "                item.to_labeled_lines()[0][0] +1,\n",
    "                item.to_labeled_lines()[0][1]\n",
    "            ))\n",
    "    \n",
    "    print(\"done with {}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/sst_train.txt\",sep=\"\\t\",header=None,names=['label','text'])\n",
    "df_train['label'] = df_train['label'].str.replace(\"__label__\",\"\")\n",
    "# df_train['label'] = df_train['label'].astype(int).astype(\"category\")\n",
    "df_train['label'] = (df_train['label'].astype(int) - 1).astype('category')\n",
    "\n",
    "df_test = pd.read_csv(\"data/sst_test.txt\",sep=\"\\t\",header=None,names=['label','text'])\n",
    "df_test['label'] = df_test['label'].str.replace(\"__label__\",\"\")\n",
    "# df_test['label'] = df_test['label'].astype(int).astype(\"category\")\n",
    "df_test['label'] = (df_test['label'].astype(int) - 1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539</th>\n",
       "      <td>0</td>\n",
       "      <td>A real snooze .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>1</td>\n",
       "      <td>No surprises .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8541</th>\n",
       "      <td>3</td>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8542</th>\n",
       "      <td>0</td>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>1</td>\n",
       "      <td>In this case zero .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        3  The Rock is destined to be the 21st Century 's...\n",
       "1        4  The gorgeously elaborate continuation of `` Th...\n",
       "2        3  Singer/composer Bryan Adams contributes a slew...\n",
       "3        2  You 'd think by now America would have had eno...\n",
       "4        3               Yet the act is still charming here .\n",
       "...    ...                                                ...\n",
       "8539     0                                    A real snooze .\n",
       "8540     1                                     No surprises .\n",
       "8541     3  We 've seen the hippie-turned-yuppie plot befo...\n",
       "8542     0  Her fans walked out muttering words like `` ho...\n",
       "8543     1                                In this case zero .\n",
       "\n",
       "[8544 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>3</td>\n",
       "      <td>An imaginative comedy/thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>4</td>\n",
       "      <td>( A ) rare , beautiful film .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>4</td>\n",
       "      <td>( An ) hilarious romantic comedy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>3</td>\n",
       "      <td>Never ( sinks ) into exploitation .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0</td>\n",
       "      <td>( U ) nrelentingly stupid .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        2                     Effective but too-tepid biopic\n",
       "1        3  If you sometimes like to go to the movies to h...\n",
       "2        4  Emerges as something rare , an issue movie tha...\n",
       "3        2  The film provides some great insight into the ...\n",
       "4        4  Offers that rare combination of entertainment ...\n",
       "...    ...                                                ...\n",
       "2205     3                   An imaginative comedy/thriller .\n",
       "2206     4                      ( A ) rare , beautiful film .\n",
       "2207     4                 ( An ) hilarious romantic comedy .\n",
       "2208     3                Never ( sinks ) into exploitation .\n",
       "2209     0                        ( U ) nrelentingly stupid .\n",
       "\n",
       "[2210 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/6y_9xhvn7tx64mnfljyvm01m0000gn/T/ipykernel_80946/3674060142.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df_train['text'] = df_train['text'].apply(strip_html)\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_train['text'] = df_train['text'].apply(remove_punctuation)\n",
    "df_train['text'] = df_train['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/6y_9xhvn7tx64mnfljyvm01m0000gn/T/ipykernel_80946/3674060142.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df_test['text'] = df_test['text'].apply(strip_html)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(remove_punctuation)\n",
    "df_test['text'] = df_test['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MULTI-LAYER PERCEPTRON (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((df_train['text'], df_train['label']))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((df_test['text'], df_test['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google News Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/267 [..............................] - ETA: 51s - loss: 1.5873 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mazeltan/Desktop/CZ4042_Group_project/env/lib/python3.11/site-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 1s 2ms/step - loss: 1.4621 - accuracy: 0.3817 - val_loss: 1.7629 - val_accuracy: 0.2878\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 0s 891us/step - loss: 1.4547 - accuracy: 0.3749 - val_loss: 1.6380 - val_accuracy: 0.2959\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 0s 874us/step - loss: 1.3914 - accuracy: 0.3940 - val_loss: 1.6015 - val_accuracy: 0.3086\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 0s 899us/step - loss: 1.3531 - accuracy: 0.4127 - val_loss: 1.5750 - val_accuracy: 0.3240\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 0s 875us/step - loss: 1.3301 - accuracy: 0.4215 - val_loss: 1.5573 - val_accuracy: 0.3348\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 0s 852us/step - loss: 1.3157 - accuracy: 0.4292 - val_loss: 1.5463 - val_accuracy: 0.3462\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 0s 839us/step - loss: 1.3063 - accuracy: 0.4371 - val_loss: 1.5376 - val_accuracy: 0.3511\n",
      "Epoch 8/50\n",
      "267/267 [==============================] - 0s 908us/step - loss: 1.2991 - accuracy: 0.4362 - val_loss: 1.5350 - val_accuracy: 0.3575\n",
      "Epoch 9/50\n",
      "267/267 [==============================] - 0s 875us/step - loss: 1.2936 - accuracy: 0.4402 - val_loss: 1.5303 - val_accuracy: 0.3597\n",
      "Epoch 10/50\n",
      "267/267 [==============================] - 0s 904us/step - loss: 1.2884 - accuracy: 0.4415 - val_loss: 1.5282 - val_accuracy: 0.3602\n",
      "Epoch 11/50\n",
      "267/267 [==============================] - 0s 694us/step - loss: 1.2837 - accuracy: 0.4434 - val_loss: 1.5292 - val_accuracy: 0.3597\n",
      "Epoch 12/50\n",
      "267/267 [==============================] - 0s 649us/step - loss: 1.2795 - accuracy: 0.4441 - val_loss: 1.5297 - val_accuracy: 0.3588\n",
      "Epoch 13/50\n",
      "267/267 [==============================] - 0s 737us/step - loss: 1.2755 - accuracy: 0.4451 - val_loss: 1.5300 - val_accuracy: 0.3597\n",
      "Epoch 14/50\n",
      "267/267 [==============================] - 0s 645us/step - loss: 1.2721 - accuracy: 0.4491 - val_loss: 1.5296 - val_accuracy: 0.3597\n",
      "Epoch 15/50\n",
      "267/267 [==============================] - 0s 1ms/step - loss: 1.2690 - accuracy: 0.4524 - val_loss: 1.5302 - val_accuracy: 0.3611\n"
     ]
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=False)  # You can set trainable to True or False based on your needs\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Batch the datasets\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,      \n",
    "    epochs=50,                                 \n",
    "    validation_data=test_dataset, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/267 [..............................] - ETA: 51s - loss: 1.6357 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mazeltan/Desktop/CZ4042_Group_project/env/lib/python3.11/site-packages/keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 1s 3ms/step - loss: 1.4519 - accuracy: 0.4155 - val_loss: 1.6886 - val_accuracy: 0.2878\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 0s 2ms/step - loss: 1.4901 - accuracy: 0.3779 - val_loss: 1.6342 - val_accuracy: 0.2919\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 0s 607us/step - loss: 1.4532 - accuracy: 0.3857 - val_loss: 1.6418 - val_accuracy: 0.2977\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 0s 617us/step - loss: 1.4155 - accuracy: 0.4088 - val_loss: 1.6999 - val_accuracy: 0.2982\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 0s 606us/step - loss: 1.3814 - accuracy: 0.4068 - val_loss: 1.8050 - val_accuracy: 0.2950\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 0s 613us/step - loss: 1.3751 - accuracy: 0.4230 - val_loss: 1.6724 - val_accuracy: 0.2995\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 1s 2ms/step - loss: 1.3631 - accuracy: 0.4240 - val_loss: 1.6771 - val_accuracy: 0.3104\n"
     ]
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=False)  # You can set trainable to True or False based on your needs\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((df_train['text'], df_train['label']))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((df_test['text'], df_test['label']))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,      \n",
    "    epochs=50,                                 \n",
    "    validation_data=test_dataset, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
