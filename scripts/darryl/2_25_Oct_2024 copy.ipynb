{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath('../scripts/scripts/'))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "\n",
    "from scripts.constants import PATH_TO_DATA, DATA_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>1</td>\n",
       "      <td>The characters are so generic and the plot so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>4</td>\n",
       "      <td>Her performance moves between heartbreak and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>2</td>\n",
       "      <td>These characters become wearisome .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review\n",
       "6204          1   The characters are so generic and the plot so...\n",
       "3237          4   Her performance moves between heartbreak and ...\n",
       "6179          2                These characters become wearisome ."
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(PATH_TO_DATA, DATA_FILE_NAME), sep='|', names=['sentiment', 'review'], encoding='latin-1')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8544, 2)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8544 entries, 0 to 8543\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  8544 non-null   int64 \n",
      " 1   review     8544 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 133.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 2, 1])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "4    2322\n",
       "2    2218\n",
       "3    1624\n",
       "5    1288\n",
       "1    1092\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>5</td>\n",
       "      <td>It 's a very valuable film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>2</td>\n",
       "      <td>The action quickly sinks into by-the-numbers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>5</td>\n",
       "      <td>One of the very best movies ever made about t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review\n",
       "3991          5                     It 's a very valuable film ...\n",
       "7807          2   The action quickly sinks into by-the-numbers ...\n",
       "1484          5   One of the very best movies ever made about t..."
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda \n",
    "The purpose of this notebook is \"To compare the performance of different Transformers architectures\".\n",
    "\n",
    "<b>General Approach</b>\n",
    "1. Research on the different types of Transformers architectures.\n",
    "2. Conduct analysis on the performance of different Transformers architectures on the given dataset.\n",
    "3. Report the analysis of performance.\n",
    "\n",
    "\n",
    "<b>References</b>\n",
    "1. https://machinelearningmastery.com/the-transformer-model/\n",
    "2. https://huggingface.co/docs/transformers/index\n",
    "3. https://pytorch.org/hub/huggingface_pytorch-transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reseach on the different types of Transformers Architectures\n",
    "\n",
    "There are multiple different types of Transformers Architectures available in the open source market now. With a myriad of options to choose from, one can only decide which one to use based on the performance of the Transformers architecture on the given dataset. In this notebook, I will be exploring the use of Transformers (and their pretrained model weights) to perform sentiment analysis on the given dataset.\n",
    "\n",
    "I will be using the `pytorch-transformers` package to implement the models. In this package, there are a total of 8 pretrained models to choose from.\n",
    "- BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\n",
    "- GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.\n",
    "- GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.\n",
    "- Transformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.\n",
    "- XLNet (from Google/CMU) released with the paper â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\n",
    "- XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.\n",
    "- RoBERTa (from Facebook), released together with the paper a Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.\n",
    "- DistilBERT (from HuggingFace), released together with the blogpost Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT by Victor Sanh, Lysandre Debut and Thomas Wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing BERT for Sentiment Analysis\n",
    "Reference: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer for BERT Model \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# This tokenization step is critical during the pre-training phase of BERT, allowing the model to effectively learn the relationships between words or sub-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# Check maximum length of sequences\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "# Model cannot perform well if the number of tokens trained on < input number of tokens\n",
    "# Therefore, a small experiment to determine if the said model tokenizer can perform decently well is to check the max number of tokens in the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='n_tokens'>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the maximum number of possible tokens\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Define pre-processing function (remove numbers and punctuations)\n",
    "def preprocess_text(text:str) -> str:\n",
    "    # Case text to lower case\n",
    "    text_lowercase = text.lower()\n",
    "    \n",
    "    # Strip whitespaces\n",
    "    text_no_ws = \" \".join([x for x in text_lowercase.split(\" \") if x != \" \"])\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text_no_punc = ''.join([x for x in text_no_ws if x not in punctuation])\n",
    "    \n",
    "    # Remove numbers\n",
    "    text_no_num = ''.join([x for x in text_no_punc if x.isalpha() or x == \" \"])\n",
    "    \n",
    "    return text_no_num\n",
    "\n",
    "df_copy['review_cleaned'] = df_copy['review'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Count number of tokens\n",
    "df_copy['n_tokens'] = df_copy['review_cleaned'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "# Display counts for tokens\n",
    "sns.boxplot(data=df_copy, x='n_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 58\n",
      "Min: 1\n"
     ]
    }
   ],
   "source": [
    "n_tokens_max, n_tokens_min = df_copy['n_tokens'].max(), df_copy['n_tokens'].min()\n",
    "print(f'Max: {n_tokens_max}\\nMin: {n_tokens_min}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `n_tokens_max` is less than 512, the model will perform decently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens \n",
    "df_copy['tokens'] = df_copy['review_cleaned'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice dataframe in features and labels\n",
    "X = df_copy[['review_cleaned']]\n",
    "y = df_copy[['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Dataset\n",
    "TEST_SIZE = 0.05\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8116, 1)\n",
      "Shape of y_train: (8116, 1)\n",
      "\n",
      "Shape of X_test: (428, 1)\n",
      "Shape of y_test: (428, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display Shapes\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape, end='\\n\\n')\n",
    "\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterables\n",
    "train_iter = pd.concat([X_train, y_train], axis=1).to_dict(orient='records')\n",
    "test_iter = pd.concat([X_test, y_test], axis=1).to_dict(orient='records')\n",
    "\n",
    "# Define Batch Size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_iter, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BERT Model\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters for BERT\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 112,241,409 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Params for BERT Model to prevent re-training\n",
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "# Display layers that require training\n",
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(batch.get(\"review_cleaned\")).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.get(\"sentiment\"))\n",
    "        \n",
    "        acc = accuracy(predictions, batch.get(\"sentiment\"))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.get(\"review_cleaned\")).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.get(\"sentiment\"))\n",
    "            \n",
    "            acc = accuracy(predictions, batch.get(\"sentiment\"))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/peanutsee/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/scripts/darryl/2_25_Oct_2024.ipynb Cell 38\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m evaluate(model, test_dataloader, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/peanutsee/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/scripts/darryl/2_25_Oct_2024.ipynb Cell 38\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m epoch_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m iterator:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/peanutsee/Desktop/Year%204%20Sem%201/CZ4042%20-%20Neural%20Network%20%26%20Deep%20Learning/Group%20Project/scripts/darryl/2_25_Oct_2024.ipynb#Y115sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     predictions \u001b[39m=\u001b[39;49m model(batch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mreview_cleaned\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49msqueeze(\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/Desktop/Year 4 Sem 1/CZ4042 - Neural Network & Deep Learning/Group Project/pyenv/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:138\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    136\u001b[0m elem_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mnext\u001b[39m(it))\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(elem) \u001b[39m==\u001b[39m elem_size \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m it):\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39meach element in list of batch should be of equal size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conduct analysis on the different types of Transformers Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the analysis of performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
