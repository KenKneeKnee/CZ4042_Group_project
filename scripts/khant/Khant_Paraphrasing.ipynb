{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85bedcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "from parrot import Parrot\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f86b4",
   "metadata": {},
   "source": [
    "# IMDB data set exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd54cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06df662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean reviews\n",
    "imdb['review'] = imdb['review'].apply(lambda x: re.sub(r'<br\\s*/?>', '', x, flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d6cb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b83be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = imdb[imdb['sentiment'] == \"positive\"]\n",
    "neg = imdb[imdb['sentiment'] == \"negative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179029f3",
   "metadata": {},
   "source": [
    "# Paraphrasing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecfe2869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=5,\n",
    "    num_beam_groups=5,\n",
    "    num_return_sequences=5,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaf5783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khant\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\khant\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\auto\\auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fab6f7e941c47b5b7739bc169dc6998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khant\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abf52fd930e4196861a6b92db0f1af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/913 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477151edb29447dabd507406ddc09f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca6eec728eb432fb28166bc2b6cde87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bb4fa85c8d4c069c313e9037a63ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dd848c11ea4545a4a40902ded1b18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbe275f89b3412188d50c9c1cc7e9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5b62b59b2c451ba9329ce68bfece88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef5b4953fd64dd08cabd59208a7279f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff02c4231047404dae98350571c0d2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a6c2343504e1daab2ce6ca428fc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5625f27d98bc4bec925a6e61bee23a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2608c9d3053a4e5dbb8b79a2ecbb0e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2b9e5/.gitattributes:   0%|          | 0.00/736 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2849d0e186af4460b165ae79ffc476bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234dfcd1ca094c37a8322dcbe2e94ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3c1ed2b9e5/README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5513ff5288144fd6aae97f0f97944caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1ed2b9e5/config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb4a5bb6fec4a74b8824f48bf0dd1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b25b4a6ac744fcca09db4bab84a1335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c1ed2b9e5/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1363b0f0734a6593446202688a229d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b3f6a5ae054526ab8d4dc744727e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51681587b57f4a4bb79fe21b3068ff4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e22f24f1df4328824065c4f80f438b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2b9e5/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74c2e63e24046ca816c6ed893efec31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f7b3bc9841466da8773f5176564567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c1ed2b9e5/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16a55a371ad4162b721cace68adb788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed2b9e5/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41ecac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parrot output:\n",
      "this model doesn't meet my expectations\n",
      "this model does not meet my expectations\n",
      "this model is not at my level of expectation\n",
      "this model is not a match for my expectations\n",
      "this model is not on par with my expectations\n",
      "this model does not live up to my expectations\n",
      "this model doesn't perform to my expectations\n",
      "--------------------------------------------------------\n",
      "Humarin's paraphraser output:\n",
      "This model is not meeting my expectations.\n",
      "I am not satisfied with the performance of this model.\n",
      "The quality of this model is not satisfactory.\n",
      "Although this model is good, I am not entirely impressed with its performance.\n",
      "My impressions of this model are not up to par.\n"
     ]
    }
   ],
   "source": [
    "phrase = \"this model is not performing up to my expectations\"\n",
    "\n",
    "print(\"Parrot output:\")\n",
    "para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False) # returns (string, len(string))\n",
    "for para_phrase in para_phrases:\n",
    "    print(para_phrase[0])\n",
    "    \n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Humarin's paraphraser output:\")\n",
    "para_phrases2 = paraphrase(phrase)\n",
    "for para_phrase in para_phrases2:\n",
    "    print(para_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9eedda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parrot output:\n",
      "a welcome relief from baseball movies that try too hard to be mythic this one is a sweet and modest and ultimately winning story\n",
      "--------------------------------------------------------\n",
      "Humarin's paraphraser output:\n",
      "Unlike baseball movies that strive to be overhyped, this story is both humble and ultimately successful.\n",
      "The sweet, modest and ultimately triumphant storyline of this baseball movie is a welcome change from those who try to steal the show.\n",
      "This baseball movie is a welcome change from the overly ambitious and overblown tale of triumphant team members, as it's genuinely sweet and modest.\n",
      "It's a welcome change from baseball movies that strive to be mythical, as it'll end up being genuinely sweet, modest, and ultimately successful.\n",
      "In a time when baseball movies strive to be mythical, this film offers reassurance and an ultimately successful story.\n"
     ]
    }
   ],
   "source": [
    "phrase = \" A welcome relief from baseball movies that try too hard to be mythic , this one is a sweet and modest and ultimately winning story .\"\n",
    "\n",
    "print(\"Parrot output:\")\n",
    "para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False,max_length=len(phrase)) # returns (string, len(string))\n",
    "for para_phrase in para_phrases:\n",
    "    print(para_phrase[0])\n",
    "    \n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Humarin's paraphraser output:\")\n",
    "para_phrases2 = paraphrase(phrase)\n",
    "for para_phrase in para_phrases2:\n",
    "    print(para_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddd3ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review: The John Van Druten Broadway hit is brought to the screen with a maximum of star power in this romantic fantasy about a modern-day witch who beguiles a successful Manhattan publisher. James Stewart may get top billing, but it is Kim Novak who steals the show as one of the most alluring witches ever to cast a spell on the movie screen. The lead pairing is, in fact, one of the movie's few weaknesses: the gray-haired Stewart seems a bit old for the role, and while it is easy to see why he falls hard for Novak, it's a little harder to understand what she finds attractive about him, as they seem mismatched in temperment and outlook. (It is one of the story's amusing conceits that witches and warlocks are portrayed as Greenwich Village beatniks and bohemians.) Curiously, the Stewart-Novak pairing would generate a lot more heat in \"Vertigo\", released the same year as this film, but then \"Vertigo\" had a compelling suspense story, and the benefit of Alfred Hitchcock's direction.The film's comic moments are mostly provided by the stellar supporting cast, including a young Jack Lemmon (as Kim's warlock brother), Elsa Lanchester (their ditzy aunt), and Ernie Kovacs (!) as a befuddled writer. Hermione Gingold even shows up in a hilarious cameo as a sort of Grand Witch. There's lots to like in this movie--wit, romance, and a great cast--that is, if you can possibly take your eyes off the enchanting Miss Novak. I have seen the movie a half a dozen times, and I never can.\n",
      "--------------------------------------------------------\n",
      "Parrot output:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khant\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The John Van Druten Broadway hit is brought to the screen with a maximum of star power in this romantic fantasy about a modern-day witch who beguiles a successful Manhattan publisher. James Stewart may get top billing, but it is Kim Novak who steals the show as one of the most alluring witches ever to cast a spell on the movie screen. The lead pairing is, in fact, one of the movie's few weaknesses: the gray-haired Stewart seems a bit old for the role, and while it is easy to see why he falls hard for Novak, it's a little harder to understand what she finds attractive about him, as they seem mismatched in temperment and outlook. (It is one of the story's amusing conceits that witches and warlocks are portrayed as Greenwich Village beatniks and bohemians.) Curiously, the Stewart-Novak pairing would generate a lot more heat in \"Vertigo\", released the same year as this film, but then \"Vertigo\" had a compelling suspense story, and the benefit of Alfred Hitchcock's direction.The film's comic moments are mostly provided by the stellar supporting cast, including a young Jack Lemmon (as Kim's warlock brother), Elsa Lanchester (their ditzy aunt), and Ernie Kovacs (!) as a befuddled writer. Hermione Gingold even shows up in a hilarious cameo as a sort of Grand Witch. There's lots to like in this movie--wit, romance, and a great cast--that is, if you can possibly take your eyes off the enchanting Miss Novak. I have seen the movie a half a dozen times, and I never can.\n",
      "--------------------------------------------------------\n",
      "Humarin's paraphraser output:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khant\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The modern-day witch who trickles down on a wealthy Manhattan publisher is the star of this romantic fantasy, with Kim Novak being cast as one of the most alluring witches to ever grace the screen. However, Stewart's appearance doesn't suit his taste at all, making him an unappealing halftime role in the film.\n",
      "In this romantic fantasy about a modern witch who befriends – and overpowers the successful Manhattan publisher - John Van Druten's Broadway hit, Kim Novak is one of the most attractive witches ever to cast on the movie screen. The lead actor, James Stewart, looks rather outcast for his role in the film, which may not have been an issue at all.\n",
      "The movie features a modern-day witch who aids aspiring publisher in their romantic fantasy, inspired by the Broadway hit John Van Druten. While James Stewart is the most popular character, Kim Novak is one of the more alluring witches to ever grace the screen. Unfortunately, Stewart's youthful appearance makes her less suitable for the lead role, which seems out of place due to his age.\n",
      "This romantic fantasy features a modern-day witch who befriends erudite Manhattan publisher, with Kim Novak being the most convincing witch to impress moviegoers. However, Stewart's age is not reflected in the film'S Elegance, which has some strong antagonism.\n",
      "A modern-day witch who tricks a wealthy Manhattan publisher is the star of this romantic fantasy, which features James Stewart as the hero. However, Kim Novak's stunning presence makes it all up against him in the movie, making for arguably the film'S weaker lead: she appears to be too old (and there aren't many actors at the theater) to justify such an investment; Stewart seems like he should be doing his best job, but then again, she falls for me.\n"
     ]
    }
   ],
   "source": [
    "phrase = imdb[\"review\"].values[random.randint(0,50000)]\n",
    "print(f'review: {phrase}')\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Parrot output:\")\n",
    "para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False) # returns (string, len(string))\n",
    "for para_phrase in para_phrases:\n",
    "    print(para_phrase[0])\n",
    "    \n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Humarin's paraphraser output:\")\n",
    "para_phrases2 = paraphrase(phrase)\n",
    "for para_phrase in para_phrases2:\n",
    "    print(para_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119f58b",
   "metadata": {},
   "source": [
    "*Parrot does not work for multi sentence strings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246f073",
   "metadata": {},
   "source": [
    "# Validating paraphrasing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf3884",
   "metadata": {},
   "source": [
    "### Sentence wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "395fce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Nltk.vader's Sentiment intensity Analyser\n",
    "sia = SIA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c968b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base score: 0.9217\n",
      "--------------------------------------------------------\n",
      "Humarin's paraphraser output:\n",
      "para score: 0.8074\n",
      "difference: 0.11429999999999996\n",
      "para score: 0.9081\n",
      "difference: 0.013599999999999945\n",
      "para score: 0.8074\n",
      "difference: 0.11429999999999996\n",
      "para score: 0.8126\n",
      "difference: 0.10909999999999997\n",
      "para score: 0.6124\n",
      "difference: 0.3092999999999999\n"
     ]
    }
   ],
   "source": [
    "phrase = 'This is an outstanding movie with a great cast. The plot is equally great'\n",
    "base_score = sia.polarity_scores(phrase)['compound']\n",
    "print(f'base score: {base_score}')\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Humarin's paraphraser output:\")\n",
    "para_phrases2 = paraphrase(phrase)\n",
    "for para_phrase in para_phrases2:\n",
    "    para_score = sia.polarity_scores(para_phrase)['compound']\n",
    "    print(f'para score: {para_score}')\n",
    "    print(f'difference: {abs(para_score - base_score)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93b7f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base score: 0.9217\n",
      "--------------------------------------------------------\n",
      "Parrot output:\n",
      "para score: 0.8934\n",
      "difference: 0.028299999999999992\n",
      "para score: 0.8934\n",
      "difference: 0.028299999999999992\n",
      "para score: 0.9217\n",
      "difference: 0.0\n",
      "para score: 0.9136\n",
      "difference: 0.008099999999999996\n",
      "para score: 0.9001\n",
      "difference: 0.021599999999999953\n",
      "para score: 0.9217\n",
      "difference: 0.0\n",
      "para score: 0.9001\n",
      "difference: 0.021599999999999953\n",
      "para score: 0.9217\n",
      "difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "phrase = 'This is an outstanding movie with a great cast. The plot is equally great'\n",
    "base_score = sia.polarity_scores(phrase)['compound']\n",
    "print(f'base score: {base_score}')\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Parrot output:\")\n",
    "para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False) # returns (string, len(string))\n",
    "for para_phrase in para_phrases:\n",
    "    para_score = sia.polarity_scores(para_phrase[0])['compound']\n",
    "    print(f'para score: {para_score}')\n",
    "    print(f'difference: {abs(para_score - base_score)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf4b5ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base score: 0.9273\n",
      "--------------------------------------------------------\n",
      "Humarin's paraphraser output:\n",
      "para score: 0.945\n",
      "difference: 0.017699999999999938\n",
      "para score: 0.9225\n",
      "difference: 0.0048000000000000265\n",
      "para score: 0.6557\n",
      "difference: 0.27160000000000006\n",
      "para score: 0.8968\n",
      "difference: 0.03049999999999997\n",
      "para score: 0.8622\n",
      "difference: 0.06510000000000005\n"
     ]
    }
   ],
   "source": [
    "phrase = imdb[\"review\"].values[random.randint(0,50000)]\n",
    "base_score = sia.polarity_scores(phrase)['compound']\n",
    "print(f'base score: {base_score}')\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "print(\"Humarin's paraphraser output:\")\n",
    "para_phrases2 = paraphrase(phrase)\n",
    "for para_phrase in para_phrases2:\n",
    "    para_score = sia.polarity_scores(para_phrase)['compound']\n",
    "    print(f'para score: {para_score}')\n",
    "    print(f'difference: {abs(para_score - base_score)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ed14d",
   "metadata": {},
   "source": [
    "Sentence wise paraphrasing works better for parrot, if sentence is actually paraphrased"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
